\chapter{Principal Component Analysis}
\label{chapter:pca}

Machine learning solutions are often designed to handle high-dimension
data. For example, the prices of houses may be affected by dozens of
factors, such as locations, sizes, years, number of floors, presence
of basements, types of materials, sizes of yards, etc.  Among all
these factors, it is natural to ask ``Which factor has the greatest
effects on the prices?''  Principal component analysis (PCA) is a
method to answer such a question.  PCA aims to {\it transform}
high-dimensional data so that the ``principal components'' can be
expressed in lower dimensions.  To put in another way, PCA aims to
discover which components have the greatest impacts in the data.
Before we get into the details of PCA, let's first review Linear
Algebra.

\section{Linear Algebra: Vector, Matrix, Projection}

Linear Algebra is a separate book by itself. This section reviews
vector, matrix, and projection.

, and eigenvalues.


% https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues

% http://www.cs.princeton.edu/courses/archive/fall08/cos429/CourseMaterials/lecture2/PCA_handout.pdf

% http://www.cs.otago.ac.nz/cosc453/student_tutorials/principal_components.pdf
